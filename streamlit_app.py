import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime

# =============================================================================
# CONFIGURAÃ‡ÃƒO DA PÃGINA
# =============================================================================
st.set_page_config(
    page_title="RelatÃ³rio de Vendas ST",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============================================================================
# CARREGAMENTO DE DADOS (Google Sheets)
# =============================================================================
@st.cache_data(ttl=1800)  # Cache 30min
def load_data():
    """Carrega dados do Google Sheets pÃºblico"""
    csv_url = (
        "https://docs.google.com/spreadsheets/d/"
        "1Ta1kAFkXne4wv4W9vpBYcqoWqSJOqToAwriSAnDT7cY/"
        "export?format=csv&gid=0"
    )
    
    try:
        df = pd.read_csv(csv_url)
        st.cache_data.clear()  # Limpa cache na primeira carga
        st.success(f"âœ… Dados carregados: {len(df):,} registos")
        return df
    except Exception as e:
        st.error(f"âŒ Erro ao carregar: {str(e)}")
        st.error("Verifique se o Google Sheets estÃ¡ pÃºblico")
        st.stop()

# =============================================================================
# PROCESSAMENTO DOS DADOS
# =============================================================================
def preprocess_data(df):
    """Processa e limpa os dados"""
    df.columns = [str(col).strip().lower().replace(' ', '_') for col in df.columns]
    
    # ConversÃµes automÃ¡ticas
    for col in df.columns:
        # Datas
        if any(x in col for x in ['data', 'date', 'dt']):
            df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
        # NÃºmeros
        elif any(x in col for x in ['valor', 'value', 'total', 'quant', 'preco', 'price']):
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # Remove linhas vazias
    df = df.dropna(subset=[col for col in df.columns if df[col].dtype in ['int64', 'float64']])
    
    return df

# =============================================================================
# FUNÃ‡ÃƒO PRINCIPAL
# =============================================================================
def main():
    st.title("ğŸ“Š RelatÃ³rio de Vendas - AnÃ¡lise Completa")
    st.markdown("---")
    
    # Carrega dados
    with st.spinner("Carregando dados..."):
        df_raw = load_data()
        df = preprocess_data(df_raw.copy())
    
    # Debug: Info dos dados
    col1, col2, col3, col4 = st.columns(4)
    with col1: st.metric("Registos", f"{len(df):,}")
    with col2: st.metric("Colunas", len(df.columns))
    with col3: st.metric("PerÃ­odo", f"{df.select_dtypes(include=['datetime']).min().min().date()} atÃ© {df.select_dtypes(include=['datetime']).max().max().date()}")
    with col4:
        if st.button("ğŸ”„ Recarregar"):
            st.cache_data.clear()
            st.rerun()
    
    # =============================================================================
    # SIDEBAR - FILTROS
    # =============================================================================
    st.sidebar.header("ğŸ” Filtros")
    
    # Detecta colunas relevantes
    date_cols = [col for col in df.columns if df[col].dtype == 'datetime64[ns]']
    num_cols = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
    cat_cols = [col for col in df.columns if df[col].dtype == 'object']
    
    df_filtered = df.copy()
    
    # Filtro data
    if date_cols:
        col_data = date_cols[0]
        min_date, max_date = df[col_data].min(), df[col_data].max()
        date_range = st.sidebar.date_input(
            "ğŸ“… PerÃ­odo",
            value=(min_date.date(), max_date.date()),
            min_value=min_date.date(),
            max_date=max_date.date()
        )
        if len(date_range) == 2:
            df_filtered = df_filtered[
                (df_filtered[col_data] >= pd.to_datetime(date_range[0])) &
                (df_filtered[col_data] <= pd.to_datetime(date_range[1]))
            ]
    
    # Filtros categÃ³ricos
    for col in cat_cols[:3]:  # Primeiros 3
        unique_vals = df_filtered[col].dropna().unique()
        if len(unique_vals) < 50:
            selected = st.sidebar.multiselect(
                f"{col.title()}",
                options=["Todos"] + sorted(unique_vals.tolist()),
                default=["Todos"]
            )
            if "Todos" not in selected:
                df_filtered = df_filtered[df_filtered[col].isin(selected)]
    
    # =============================================================================
    # KPIs PRINCIPAIS
    # =============================================================================
    st.header("ğŸ’° Indicadores Principais")
    
    num_metrics = []
    for col in num_cols[:3]:
        total = df_filtered[col].sum()
        media = df_filtered[col].mean()
        num_metrics.extend([total, media])
    
    cols = st.columns(min(6, len(num_metrics)))
    for i, val in enumerate(num_metrics):
        with cols[i % len(cols)]:
            st.metric("MÃ©trica", f"{val:,.2f}")
    
    # =============================================================================
    # GRÃFICOS
    # =============================================================================
    st.header("ğŸ“ˆ VisualizaÃ§Ãµes")
    
    tab1, tab2, tab3 = st.tabs(["Vendas por Tempo", "Top Performers", "DistribuiÃ§Ã£o"])
    
    with tab1:
        if date_cols and num_cols:
            col_date, col_num = date_cols[0], num_cols[0]
            vendas_tempo = df_filtered.groupby(col_date.dt.date)[col_num].sum().reset_index()
            
            fig = px.line(vendas_tempo, x=col_date, y=col_num, 
                         title="EvoluÃ§Ã£o das Vendas", markers=True)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        if cat_cols and num_cols:
            col_cat, col_num = cat_cols[0], num_cols[0]
            top_cat = df_filtered.groupby(col_cat)[col_num].sum().nlargest(10).reset_index()
            
           

